{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. gensim实践：\n",
    "\n",
    "1. 读取预处理好的数据\n",
    "2. 训练\n",
    "3. 完事"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据集路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_data_path = 'data/merged_train_test_seg_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merger_data_path data size 102871\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>方向机 重 助力 泵 方向机 都 换 新 都 换 助力 泵 方向机 换 方向机 带 助力 重...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>奔驰 ML500 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 有发 一下 发动...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010 款 宝马X1 2011 年 出厂 20 排量 通用 6L45 变速箱 原地 换挡 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30V6 发动机 号 位置 照片 最好 右侧 排气管 上方 缸体 上 靠近 变速箱 是不是 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012 款 奔驰 c180 维修保养 动力 值得 拥有 家庭 用车 入手 维修保养 费用 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  方向机 重 助力 泵 方向机 都 换 新 都 换 助力 泵 方向机 换 方向机 带 助力 重...\n",
       "1  奔驰 ML500 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 有发 一下 发动...\n",
       "2  2010 款 宝马X1 2011 年 出厂 20 排量 通用 6L45 变速箱 原地 换挡 ...\n",
       "3  30V6 发动机 号 位置 照片 最好 右侧 排气管 上方 缸体 上 靠近 变速箱 是不是 ...\n",
       "4  2012 款 奔驰 c180 维修保养 动力 值得 拥有 家庭 用车 入手 维修保养 费用 ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_df = pd.read_csv(merger_data_path,header=None)\n",
    "print('merger_data_path data size {}'.format(len(merger_df)))\n",
    "merger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型创建\n",
    "\n",
    "Gensim中 Word2Vec 模型的期望输入是进过分词的句子列表，即是某个二维数组。这里我们暂时使用 Python 内置的数组，不过其在输入数据集较大的情况下会占用大量的 RAM。Gensim 本身只是要求能够迭代的有序句子列表，因此在工程实践中我们可以使用自定义的生成器，只在内存中保存单条语句。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 参数\n",
    "+ min_count\n",
    "\n",
    "在不同大小的语料集中，我们对于基准词频的需求也是不一样的。譬如在较大的语料集中，我们希望忽略那些只出现过一两次的单词，这里我们就可以通过设置min_count参数进行控制。一般而言，合理的参数值会设置在0~100之间。\n",
    "\n",
    "+ size\n",
    "\n",
    "size参数主要是用来设置神经网络的层数，Word2Vec 中的默认值是设置为100层。更大的层次设置意味着更多的输入数据，不过也能提升整体的准确度，合理的设置范围为 10~数百。\n",
    "\n",
    "+ workers\n",
    "\n",
    "workers参数用于设置并发训练时候的线程数，不过仅当Cython安装的情况下才会起作用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 引入 word2vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "\n",
    "# 引入日志配置\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/merged_train_test_seg_data.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-18 23:22:36,886 : INFO : collecting all words and their counts\n",
      "2020-03-18 23:22:36,887 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-03-18 23:22:37,066 : INFO : PROGRESS: at sentence #10000, processed 941657 words, keeping 36796 word types\n",
      "2020-03-18 23:22:37,265 : INFO : PROGRESS: at sentence #20000, processed 1897796 words, keeping 54149 word types\n",
      "2020-03-18 23:22:37,448 : INFO : PROGRESS: at sentence #30000, processed 2842477 words, keeping 66984 word types\n",
      "2020-03-18 23:22:37,634 : INFO : PROGRESS: at sentence #40000, processed 3759167 words, keeping 77921 word types\n",
      "2020-03-18 23:22:37,832 : INFO : PROGRESS: at sentence #50000, processed 4736386 words, keeping 87832 word types\n",
      "2020-03-18 23:22:38,058 : INFO : PROGRESS: at sentence #60000, processed 5775137 words, keeping 97810 word types\n",
      "2020-03-18 23:22:38,268 : INFO : PROGRESS: at sentence #70000, processed 6837177 words, keeping 107437 word types\n",
      "2020-03-18 23:22:38,450 : INFO : PROGRESS: at sentence #80000, processed 7783493 words, keeping 115575 word types\n",
      "2020-03-18 23:22:38,641 : INFO : PROGRESS: at sentence #90000, processed 8645033 words, keeping 123503 word types\n",
      "2020-03-18 23:22:38,815 : INFO : PROGRESS: at sentence #100000, processed 9498123 words, keeping 130550 word types\n",
      "2020-03-18 23:22:38,872 : INFO : collected 132569 word types from a corpus of 9748591 raw words and 102871 sentences\n",
      "2020-03-18 23:22:38,873 : INFO : Loading a fresh vocabulary\n",
      "2020-03-18 23:22:38,942 : INFO : effective_min_count=5 retains 32905 unique words (24% of original 132569, drops 99664)\n",
      "2020-03-18 23:22:38,942 : INFO : effective_min_count=5 leaves 9598795 word corpus (98% of original 9748591, drops 149796)\n",
      "2020-03-18 23:22:39,008 : INFO : deleting the raw counts dictionary of 132569 items\n",
      "2020-03-18 23:22:39,024 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-03-18 23:22:39,024 : INFO : downsampling leaves estimated 8611596 word corpus (89.7% of prior 9598795)\n",
      "2020-03-18 23:22:39,080 : INFO : estimated required memory for 32905 words and 200 dimensions: 69100500 bytes\n",
      "2020-03-18 23:22:39,080 : INFO : resetting layer weights\n",
      "2020-03-18 23:22:39,391 : INFO : training model with 8 workers on 32905 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-03-18 23:22:40,394 : INFO : EPOCH 1 - PROGRESS: at 23.47% examples, 2021958 words/s, in_qsize 10, out_qsize 0\n",
      "2020-03-18 23:22:41,407 : INFO : EPOCH 1 - PROGRESS: at 47.80% examples, 2044392 words/s, in_qsize 15, out_qsize 2\n",
      "2020-03-18 23:22:42,414 : INFO : EPOCH 1 - PROGRESS: at 70.12% examples, 2066039 words/s, in_qsize 15, out_qsize 0\n",
      "2020-03-18 23:22:43,411 : INFO : EPOCH 1 - PROGRESS: at 96.73% examples, 2081917 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-18 23:22:43,535 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-18 23:22:43,535 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-18 23:22:43,535 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-18 23:22:43,540 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-18 23:22:43,540 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-18 23:22:43,542 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-18 23:22:43,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-18 23:22:43,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-18 23:22:43,550 : INFO : EPOCH - 1 : training on 9748591 raw words (8611563 effective words) took 4.1s, 2077180 effective words/s\n",
      "2020-03-18 23:22:44,554 : INFO : EPOCH 2 - PROGRESS: at 23.14% examples, 1992087 words/s, in_qsize 15, out_qsize 0\n",
      "2020-03-18 23:22:45,557 : INFO : EPOCH 2 - PROGRESS: at 47.33% examples, 2026872 words/s, in_qsize 14, out_qsize 2\n",
      "2020-03-18 23:22:46,562 : INFO : EPOCH 2 - PROGRESS: at 69.06% examples, 2034238 words/s, in_qsize 10, out_qsize 1\n",
      "2020-03-18 23:22:47,560 : INFO : EPOCH 2 - PROGRESS: at 94.06% examples, 2032116 words/s, in_qsize 14, out_qsize 1\n",
      "2020-03-18 23:22:47,735 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-18 23:22:47,735 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-18 23:22:47,735 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-18 23:22:47,749 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-18 23:22:47,750 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-18 23:22:47,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-18 23:22:47,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-18 23:22:47,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-18 23:22:47,756 : INFO : EPOCH - 2 : training on 9748591 raw words (8611932 effective words) took 4.2s, 2048589 effective words/s\n",
      "2020-03-18 23:22:48,749 : INFO : EPOCH 3 - PROGRESS: at 23.67% examples, 2038273 words/s, in_qsize 16, out_qsize 0\n",
      "2020-03-18 23:22:49,763 : INFO : EPOCH 3 - PROGRESS: at 48.65% examples, 2082796 words/s, in_qsize 3, out_qsize 1\n",
      "2020-03-18 23:22:50,762 : INFO : EPOCH 3 - PROGRESS: at 71.24% examples, 2096296 words/s, in_qsize 16, out_qsize 0\n",
      "2020-03-18 23:22:51,763 : INFO : EPOCH 3 - PROGRESS: at 97.29% examples, 2091083 words/s, in_qsize 14, out_qsize 1\n",
      "2020-03-18 23:22:51,842 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-18 23:22:51,843 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-18 23:22:51,848 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-18 23:22:51,852 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-18 23:22:51,853 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-18 23:22:51,857 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-18 23:22:51,859 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-18 23:22:51,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-18 23:22:51,861 : INFO : EPOCH - 3 : training on 9748591 raw words (8611948 effective words) took 4.1s, 2099986 effective words/s\n",
      "2020-03-18 23:22:52,866 : INFO : EPOCH 4 - PROGRESS: at 23.56% examples, 2025208 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-18 23:22:53,878 : INFO : EPOCH 4 - PROGRESS: at 47.33% examples, 2017515 words/s, in_qsize 15, out_qsize 1\n",
      "2020-03-18 23:22:54,878 : INFO : EPOCH 4 - PROGRESS: at 69.81% examples, 2054085 words/s, in_qsize 15, out_qsize 0\n",
      "2020-03-18 23:22:55,879 : INFO : EPOCH 4 - PROGRESS: at 96.27% examples, 2068849 words/s, in_qsize 16, out_qsize 0\n",
      "2020-03-18 23:22:55,989 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-18 23:22:55,989 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-18 23:22:55,989 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-18 23:22:55,997 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-18 23:22:55,999 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-18 23:22:55,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-18 23:22:56,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-18 23:22:56,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-18 23:22:56,004 : INFO : EPOCH - 4 : training on 9748591 raw words (8611404 effective words) took 4.1s, 2079773 effective words/s\n",
      "2020-03-18 23:22:56,996 : INFO : EPOCH 5 - PROGRESS: at 24.02% examples, 2074062 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-18 23:22:58,013 : INFO : EPOCH 5 - PROGRESS: at 48.72% examples, 2090032 words/s, in_qsize 15, out_qsize 0\n",
      "2020-03-18 23:22:59,015 : INFO : EPOCH 5 - PROGRESS: at 71.34% examples, 2101725 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-18 23:23:00,017 : INFO : EPOCH 5 - PROGRESS: at 95.68% examples, 2062377 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-18 23:23:00,141 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-18 23:23:00,141 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-18 23:23:00,141 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-18 23:23:00,152 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-18 23:23:00,153 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-18 23:23:00,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-18 23:23:00,161 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-18 23:23:00,162 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-18 23:23:00,163 : INFO : EPOCH - 5 : training on 9748591 raw words (8611558 effective words) took 4.2s, 2071884 effective words/s\n",
      "2020-03-18 23:23:00,164 : INFO : training on a 48742955 raw words (43058405 effective words) took 20.8s, 2073782 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(LineSentence(merger_data_path), workers=8,min_count=5,size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查找最近的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-18 23:23:57,303 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('东南', 0.8520945310592651),\n",
       " ('海马', 0.838854193687439),\n",
       " ('名爵', 0.8372061252593994),\n",
       " ('铃木', 0.8324585556983948),\n",
       " ('东风风行', 0.8304704427719116),\n",
       " ('江淮', 0.8286133408546448),\n",
       " ('猎豹', 0.8283058404922485),\n",
       " ('二代', 0.8249144554138184),\n",
       " ('瑞虎5', 0.8204711675643921),\n",
       " ('鹰', 0.8132823705673218)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['奇瑞'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path='data/wv/word2vec.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-18 23:24:21,878 : INFO : saving Word2Vec object under data/wv/word2vec.model, separately None\n",
      "2020-03-18 23:24:21,878 : INFO : not storing attribute vectors_norm\n",
      "2020-03-18 23:24:21,879 : INFO : not storing attribute cum_table\n",
      "2020-03-18 23:24:22,574 : INFO : saved data/wv/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model.save(save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-18 23:24:26,958 : INFO : loading Word2Vec object from data/wv/word2vec.model\n",
      "2020-03-18 23:24:27,271 : INFO : loading wv recursively from data/wv/word2vec.model.wv.* with mmap=None\n",
      "2020-03-18 23:24:27,271 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-03-18 23:24:27,271 : INFO : loading vocabulary recursively from data/wv/word2vec.model.vocabulary.* with mmap=None\n",
      "2020-03-18 23:24:27,271 : INFO : loading trainables recursively from data/wv/word2vec.model.trainables.* with mmap=None\n",
      "2020-03-18 23:24:27,271 : INFO : setting ignored attribute cum_table to None\n",
      "2020-03-18 23:24:27,271 : INFO : loaded data/wv/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-18 23:24:30,486 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('东南', 0.8520945310592651),\n",
       " ('海马', 0.838854193687439),\n",
       " ('名爵', 0.8372061252593994),\n",
       " ('铃木', 0.8324585556983948),\n",
       " ('东风风行', 0.8304704427719116),\n",
       " ('江淮', 0.8286133408546448),\n",
       " ('猎豹', 0.8283058404922485),\n",
       " ('二代', 0.8249144554138184),\n",
       " ('瑞虎5', 0.8204711675643921),\n",
       " ('鹰', 0.8132823705673218)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['奇瑞'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://radimrehurek.com/gensim/models/word2vec.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
